{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188c1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from norfair import Detection, Tracker\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f25077",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../data/people_walking.mp4\" #video path\n",
    "\n",
    " #\"n\" so it is nano model, faster. \n",
    " #It is trained by COCO dataset that includes 80 different labels \n",
    " #I used nano model but you can use small, medium,...\n",
    "model = YOLO(\"../yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80e273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"../reid_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d988d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(image):\n",
    "    image = cv2.resize(image, (128,256))\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image.astype(np.float32), axis=0)\n",
    "    interpreter.set_tensor((input_details[0]['index']), image)\n",
    "    interpreter.invoke()\n",
    "    return interpreter.get_tensor(output_details[0]['index'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe3098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) /(np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76748d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_id():\n",
    "    return str(uuid.uuid4())[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5437c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(distance_function=\"euclidean\", distance_threshold=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ba7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened:\n",
    "    print(\"Video could not open\")\n",
    "    exit()\n",
    "\n",
    "unique_ids = set()\n",
    "reid_db = {} #track_id : embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf6d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 1 handbag, 55.8ms\n",
      "Speed: 1.5ms preprocess, 55.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 1 handbag, 45.6ms\n",
      "Speed: 1.5ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 1 handbag, 43.0ms\n",
      "Speed: 1.2ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 handbag, 43.4ms\n",
      "Speed: 2.0ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 handbags, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 handbags, 44.3ms\n",
      "Speed: 1.3ms preprocess, 44.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 handbag, 44.1ms\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 handbag, 45.9ms\n",
      "Speed: 1.2ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 handbag, 41.9ms\n",
      "Speed: 1.3ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 handbag, 42.5ms\n",
      "Speed: 1.2ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 41.9ms\n",
      "Speed: 1.2ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 1 umbrella, 1 handbag, 38.4ms\n",
      "Speed: 1.3ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 umbrella, 37.9ms\n",
      "Speed: 1.3ms preprocess, 37.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 umbrella, 38.3ms\n",
      "Speed: 1.2ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 1 umbrella, 40.2ms\n",
      "Speed: 1.2ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 1 umbrella, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 backpacks, 1 umbrella, 43.1ms\n",
      "Speed: 1.2ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 umbrella, 42.7ms\n",
      "Speed: 1.3ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 umbrella, 44.1ms\n",
      "Speed: 1.2ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 umbrella, 45.1ms\n",
      "Speed: 1.2ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 umbrella, 43.4ms\n",
      "Speed: 1.2ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 umbrella, 40.8ms\n",
      "Speed: 1.4ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 41.0ms\n",
      "Speed: 1.2ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 handbag, 43.3ms\n",
      "Speed: 1.2ms preprocess, 43.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 1 handbag, 42.7ms\n",
      "Speed: 1.2ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 1 handbag, 44.4ms\n",
      "Speed: 1.1ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 backpacks, 1 handbag, 43.6ms\n",
      "Speed: 1.2ms preprocess, 43.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 1 handbag, 38.6ms\n",
      "Speed: 1.2ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 2 handbags, 40.7ms\n",
      "Speed: 1.4ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 handbags, 43.6ms\n",
      "Speed: 1.2ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 handbags, 1 skateboard, 39.9ms\n",
      "Speed: 1.6ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 1 skateboard, 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 skateboard, 38.0ms\n",
      "Speed: 1.3ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 40.5ms\n",
      "Speed: 1.3ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 38.3ms\n",
      "Speed: 1.2ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 38.0ms\n",
      "Speed: 1.4ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 1 handbag, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 39.0ms\n",
      "Speed: 1.3ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 1 handbag, 43.0ms\n",
      "Speed: 1.2ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 41.8ms\n",
      "Speed: 1.2ms preprocess, 41.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 43.1ms\n",
      "Speed: 1.4ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 handbags, 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 38.5ms\n",
      "Speed: 1.3ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 handbags, 48.6ms\n",
      "Speed: 1.1ms preprocess, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 handbags, 40.6ms\n",
      "Speed: 1.3ms preprocess, 40.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 handbags, 37.7ms\n",
      "Speed: 1.2ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 3 handbags, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 4 handbags, 40.8ms\n",
      "Speed: 1.2ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 4 handbags, 37.0ms\n",
      "Speed: 1.2ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 4 handbags, 38.8ms\n",
      "Speed: 1.1ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 skateboard, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 handbags, 37.1ms\n",
      "Speed: 1.2ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 handbags, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 handbags, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 3 handbags, 37.1ms\n",
      "Speed: 1.3ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 handbags, 1 skateboard, 38.2ms\n",
      "Speed: 1.4ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 3 handbags, 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 1 handbag, 3 skateboards, 1 surfboard, 42.9ms\n",
      "Speed: 1.4ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 1 handbag, 42.2ms\n",
      "Speed: 1.3ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 1 handbag, 1 skateboard, 43.1ms\n",
      "Speed: 1.3ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 1 handbag, 2 skateboards, 40.5ms\n",
      "Speed: 1.2ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 1 handbag, 1 skateboard, 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 handbags, 46.0ms\n",
      "Speed: 1.6ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 1 handbag, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 handbags, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 2 handbags, 41.8ms\n",
      "Speed: 1.2ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 2 handbags, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 backpack, 1 handbag, 44.3ms\n",
      "Speed: 1.2ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 1 handbag, 42.4ms\n",
      "Speed: 2.2ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 39.4ms\n",
      "Speed: 1.1ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 1 handbag, 38.7ms\n",
      "Speed: 1.2ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 38.3ms\n",
      "Speed: 1.2ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 handbags, 38.3ms\n",
      "Speed: 1.2ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 1 handbag, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 38.2ms\n",
      "Speed: 1.2ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 38.3ms\n",
      "Speed: 1.1ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 handbags, 44.7ms\n",
      "Speed: 1.2ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 handbags, 40.0ms\n",
      "Speed: 1.4ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 handbags, 37.3ms\n",
      "Speed: 1.4ms preprocess, 37.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 handbags, 38.7ms\n",
      "Speed: 1.2ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 42.5ms\n",
      "Speed: 1.2ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 39.1ms\n",
      "Speed: 1.4ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 3 handbags, 38.5ms\n",
      "Speed: 1.4ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 4 handbags, 38.5ms\n",
      "Speed: 1.4ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 3 handbags, 42.5ms\n",
      "Speed: 1.3ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 3 handbags, 43.5ms\n",
      "Speed: 1.6ms preprocess, 43.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 3 handbags, 42.6ms\n",
      "Speed: 1.2ms preprocess, 42.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 3 handbags, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 4 handbags, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 4 handbags, 39.6ms\n",
      "Speed: 1.2ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 3 handbags, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 handbags, 41.6ms\n",
      "Speed: 1.3ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 2 handbags, 39.0ms\n",
      "Speed: 1.2ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 backpack, 2 handbags, 38.8ms\n",
      "Speed: 1.3ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 backpack, 2 handbags, 37.9ms\n",
      "Speed: 1.2ms preprocess, 37.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 backpack, 2 handbags, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 backpack, 2 handbags, 39.1ms\n",
      "Speed: 1.2ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 3 handbags, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 handbags, 39.0ms\n",
      "Speed: 1.2ms preprocess, 39.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 3 handbags, 38.4ms\n",
      "Speed: 1.4ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 handbags, 40.8ms\n",
      "Speed: 1.2ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 handbags, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 4 handbags, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 4 handbags, 38.8ms\n",
      "Speed: 1.2ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 4 handbags, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 4 handbags, 37.6ms\n",
      "Speed: 1.3ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 4 handbags, 38.4ms\n",
      "Speed: 1.3ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 handbags, 38.8ms\n",
      "Speed: 1.2ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 handbags, 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 handbags, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 handbag, 36.9ms\n",
      "Speed: 1.3ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 handbags, 38.6ms\n",
      "Speed: 1.2ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 backpack, 2 handbags, 1 skateboard, 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 handbags, 38.1ms\n",
      "Speed: 1.4ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 backpack, 3 handbags, 2 skateboards, 38.7ms\n",
      "Speed: 1.2ms preprocess, 38.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 handbags, 2 skateboards, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 handbag, 2 skateboards, 38.9ms\n",
      "Speed: 1.4ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 2 skateboards, 40.2ms\n",
      "Speed: 1.3ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 handbag, 2 skateboards, 42.4ms\n",
      "Speed: 1.3ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 handbag, 1 skateboard, 41.8ms\n",
      "Speed: 1.1ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 backpacks, 1 handbag, 42.9ms\n",
      "Speed: 1.3ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 1 handbag, 44.4ms\n",
      "Speed: 1.8ms preprocess, 44.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 handbags, 42.7ms\n",
      "Speed: 1.2ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 backpack, 2 handbags, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 backpack, 2 handbags, 41.3ms\n",
      "Speed: 2.1ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 backpacks, 2 handbags, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 backpacks, 2 handbags, 42.1ms\n",
      "Speed: 1.3ms preprocess, 42.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 backpacks, 2 handbags, 42.5ms\n",
      "Speed: 1.4ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 1 handbag, 37.5ms\n",
      "Speed: 1.1ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 backpacks, 1 handbag, 1 suitcase, 39.0ms\n",
      "Speed: 1.5ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 1 handbag, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 2 handbags, 40.1ms\n",
      "Speed: 1.6ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 handbags, 41.3ms\n",
      "Speed: 1.2ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 handbags, 40.6ms\n",
      "Speed: 1.4ms preprocess, 40.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 handbags, 40.9ms\n",
      "Speed: 1.4ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 handbag, 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 handbags, 42.6ms\n",
      "Speed: 1.5ms preprocess, 42.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 43.0ms\n",
      "Speed: 1.8ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 handbags, 1 suitcase, 44.3ms\n",
      "Speed: 1.1ms preprocess, 44.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 3 handbags, 41.8ms\n",
      "Speed: 1.3ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 3 handbags, 45.5ms\n",
      "Speed: 2.9ms preprocess, 45.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 3 handbags, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 42.3ms\n",
      "Speed: 1.2ms preprocess, 42.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 4 handbags, 41.8ms\n",
      "Speed: 1.2ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 handbags, 42.0ms\n",
      "Speed: 2.1ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 handbags, 41.2ms\n",
      "Speed: 1.1ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 handbags, 44.3ms\n",
      "Speed: 1.3ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 handbags, 1 skateboard, 41.2ms\n",
      "Speed: 1.5ms preprocess, 41.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 skateboard, 44.5ms\n",
      "Speed: 1.2ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 handbags, 1 skateboard, 42.2ms\n",
      "Speed: 1.2ms preprocess, 42.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 1 skateboard, 42.4ms\n",
      "Speed: 1.2ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 handbags, 1 suitcase, 49.4ms\n",
      "Speed: 1.4ms preprocess, 49.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 4 handbags, 1 suitcase, 42.5ms\n",
      "Speed: 1.2ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 handbags, 42.1ms\n",
      "Speed: 1.3ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 handbags, 42.3ms\n",
      "Speed: 1.2ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 handbags, 40.7ms\n",
      "Speed: 2.1ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 backpacks, 4 handbags, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 3 handbags, 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 4 handbags, 43.8ms\n",
      "Speed: 1.3ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 handbags, 40.3ms\n",
      "Speed: 1.4ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 4 handbags, 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 4 handbags, 38.6ms\n",
      "Speed: 1.3ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 handbags, 37.9ms\n",
      "Speed: 1.1ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 handbags, 41.0ms\n",
      "Speed: 1.2ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 handbags, 1 suitcase, 38.8ms\n",
      "Speed: 1.4ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 38.8ms\n",
      "Speed: 1.3ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 43.3ms\n",
      "Speed: 1.3ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 3 handbags, 43.3ms\n",
      "Speed: 1.9ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 handbags, 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 4 handbags, 42.9ms\n",
      "Speed: 1.7ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 handbags, 44.7ms\n",
      "Speed: 1.1ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 43.6ms\n",
      "Speed: 1.2ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 handbags, 43.3ms\n",
      "Speed: 1.2ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 handbags, 43.4ms\n",
      "Speed: 2.2ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 handbags, 43.1ms\n",
      "Speed: 1.2ms preprocess, 43.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 handbag, 41.7ms\n",
      "Speed: 1.3ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 40.0ms\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 handbags, 44.0ms\n",
      "Speed: 1.3ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 handbags, 1 skateboard, 39.7ms\n",
      "Speed: 1.2ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 1 skateboard, 37.9ms\n",
      "Speed: 1.3ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 1 skateboard, 40.6ms\n",
      "Speed: 1.1ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 handbags, 3 skateboards, 42.2ms\n",
      "Speed: 1.4ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 1 skateboard, 42.5ms\n",
      "Speed: 1.2ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 4 handbags, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 handbags, 37.6ms\n",
      "Speed: 1.2ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 handbags, 38.2ms\n",
      "Speed: 1.2ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 handbags, 39.8ms\n",
      "Speed: 1.2ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 4 handbags, 43.7ms\n",
      "Speed: 1.2ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 40.9ms\n",
      "Speed: 1.4ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 5 handbags, 37.7ms\n",
      "Speed: 1.2ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 5 handbags, 38.6ms\n",
      "Speed: 1.4ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 handbags, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 handbags, 38.7ms\n",
      "Speed: 1.2ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 44.0ms\n",
      "Speed: 1.3ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 42.5ms\n",
      "Speed: 1.4ms preprocess, 42.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 45.4ms\n",
      "Speed: 1.1ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 44.1ms\n",
      "Speed: 1.2ms preprocess, 44.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 handbags, 1 suitcase, 42.0ms\n",
      "Speed: 1.3ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 handbags, 41.9ms\n",
      "Speed: 1.3ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 42.9ms\n",
      "Speed: 1.3ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 handbags, 42.3ms\n",
      "Speed: 1.2ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 backpack, 2 handbags, 37.2ms\n",
      "Speed: 1.4ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 handbags, 38.6ms\n",
      "Speed: 1.2ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 handbags, 40.5ms\n",
      "Speed: 1.1ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 handbags, 42.4ms\n",
      "Speed: 2.1ms preprocess, 42.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 handbag, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 handbag, 1 suitcase, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 handbag, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 handbag, 39.3ms\n",
      "Speed: 1.2ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 handbag, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)[0]\n",
    "    detections = []\n",
    "    new_reid_matches = {} # detectionindex : matched_id\n",
    "\n",
    "    for i, box in enumerate(results.boxes):\n",
    "        cls_id = int(box.cls[0])\n",
    "\n",
    "        if model.names[cls_id] == \"person\":\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            if conf > 70:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cx, cy = int((x1 + x2) / 2), int((y1+ y2) /2)\n",
    "\n",
    "                person_crop = frame[y1:y2, x1:x2]\n",
    "                if person_crop.size == 0:\n",
    "                    continue\n",
    "\n",
    "                embedding = get_embedding(person_crop)\n",
    "                matched_id = None\n",
    "\n",
    "                for known_id, known_embedding in reid_db.items():\n",
    "                    if cosine_similarity(embedding, known_embedding) > 0.70:\n",
    "                        matched_id = known_id\n",
    "                        break\n",
    "\n",
    "                if matched_id is None:\n",
    "                    matched_id = generate_new_id()\n",
    "                    reid_db[matched_id] = embedding\n",
    "                else: # Burayla sonradan oynayabilirim.\n",
    "                    reid_db[matched_id] = embedding \n",
    "            \n",
    "                unique_ids.add(matched_id)\n",
    "                new_reid_matches[i] = matched_id\n",
    "\n",
    "                detections.append(Detection(points=np.array([[cx, cy]]), scores=np.array([conf])))\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 117, 44), 2)\n",
    "                label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 117, 44), 2)\n",
    "\n",
    "    \n",
    "    tracked_objects = tracker.update(detections)\n",
    "\n",
    "    for i, obj in enumerate(tracked_objects):\n",
    "        if obj.live_points == 0:\n",
    "            continue\n",
    "        \n",
    "        x, y = obj.estimate[0]\n",
    "\n",
    "        track_id = list(new_reid_matches.values())[i] if i < len(new_reid_matches) else \"X\"\n",
    "\n",
    "        cv2.putText(frame, f\"ID: {track_id}\", (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 117, 44), 2)\n",
    "        \n",
    "\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Human Count: {len(unique_ids)}\", cv2.FONT_HERSHEY_COMPLEX, 1, 2)\n",
    "    x = frame.shape[1] - text_width - 10\n",
    "    y = text_height + 10\n",
    "    cv2.putText(frame, f\"Human Count: {len(unique_ids)}\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 117, 44), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Test Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704eeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
